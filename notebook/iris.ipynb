{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17254419-c3ff-4498-aab0-b30ed3b37b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.317678\n",
      "Epoch 2/100, Train Loss: 1.316481\n",
      "Epoch 3/100, Train Loss: 1.315292\n",
      "Epoch 4/100, Train Loss: 1.314183\n",
      "Epoch 5/100, Train Loss: 1.313030\n",
      "Epoch 6/100, Train Loss: 1.311960\n",
      "Epoch 7/100, Train Loss: 1.310871\n",
      "Epoch 8/100, Train Loss: 1.309776\n",
      "Epoch 9/100, Train Loss: 1.308748\n",
      "Epoch 10/100, Train Loss: 1.307732\n",
      "Epoch 11/100, Train Loss: 1.306732\n",
      "Epoch 12/100, Train Loss: 1.305681\n",
      "Epoch 13/100, Train Loss: 1.304705\n",
      "Epoch 14/100, Train Loss: 1.303746\n",
      "Epoch 15/100, Train Loss: 1.302777\n",
      "Epoch 16/100, Train Loss: 1.301811\n",
      "Epoch 17/100, Train Loss: 1.300886\n",
      "Epoch 18/100, Train Loss: 1.299971\n",
      "Epoch 19/100, Train Loss: 1.299011\n",
      "Epoch 20/100, Train Loss: 1.298145\n",
      "Epoch 21/100, Train Loss: 1.297255\n",
      "Epoch 22/100, Train Loss: 1.296344\n",
      "Epoch 23/100, Train Loss: 1.295458\n",
      "Epoch 24/100, Train Loss: 1.294591\n",
      "Epoch 25/100, Train Loss: 1.293718\n",
      "Epoch 26/100, Train Loss: 1.292877\n",
      "Epoch 27/100, Train Loss: 1.292031\n",
      "Epoch 28/100, Train Loss: 1.291168\n",
      "Epoch 29/100, Train Loss: 1.290345\n",
      "Epoch 30/100, Train Loss: 1.289543\n",
      "Epoch 31/100, Train Loss: 1.288682\n",
      "Epoch 32/100, Train Loss: 1.287909\n",
      "Epoch 33/100, Train Loss: 1.287138\n",
      "Epoch 34/100, Train Loss: 1.286307\n",
      "Epoch 35/100, Train Loss: 1.285491\n",
      "Epoch 36/100, Train Loss: 1.284754\n",
      "Epoch 37/100, Train Loss: 1.283971\n",
      "Epoch 38/100, Train Loss: 1.283226\n",
      "Epoch 39/100, Train Loss: 1.282451\n",
      "Epoch 40/100, Train Loss: 1.281672\n",
      "Epoch 41/100, Train Loss: 1.280908\n",
      "Epoch 42/100, Train Loss: 1.280178\n",
      "Epoch 43/100, Train Loss: 1.279491\n",
      "Epoch 44/100, Train Loss: 1.278769\n",
      "Epoch 45/100, Train Loss: 1.277991\n",
      "Epoch 46/100, Train Loss: 1.277334\n",
      "Epoch 47/100, Train Loss: 1.276557\n",
      "Epoch 48/100, Train Loss: 1.275887\n",
      "Epoch 49/100, Train Loss: 1.275157\n",
      "Epoch 50/100, Train Loss: 1.274383\n",
      "Epoch 51/100, Train Loss: 1.273768\n",
      "Epoch 52/100, Train Loss: 1.273065\n",
      "Epoch 53/100, Train Loss: 1.272313\n",
      "Epoch 54/100, Train Loss: 1.271606\n",
      "Epoch 55/100, Train Loss: 1.270910\n",
      "Epoch 56/100, Train Loss: 1.270239\n",
      "Epoch 57/100, Train Loss: 1.269501\n",
      "Epoch 58/100, Train Loss: 1.268839\n",
      "Epoch 59/100, Train Loss: 1.268132\n",
      "Epoch 60/100, Train Loss: 1.267425\n",
      "Epoch 61/100, Train Loss: 1.266762\n",
      "Epoch 62/100, Train Loss: 1.266044\n",
      "Epoch 63/100, Train Loss: 1.265379\n",
      "Epoch 64/100, Train Loss: 1.264676\n",
      "Epoch 65/100, Train Loss: 1.263996\n",
      "Epoch 66/100, Train Loss: 1.263315\n",
      "Epoch 67/100, Train Loss: 1.262688\n",
      "Epoch 68/100, Train Loss: 1.262005\n",
      "Epoch 69/100, Train Loss: 1.261288\n",
      "Epoch 70/100, Train Loss: 1.260578\n",
      "Epoch 71/100, Train Loss: 1.259970\n",
      "Epoch 72/100, Train Loss: 1.259263\n",
      "Epoch 73/100, Train Loss: 1.258584\n",
      "Epoch 74/100, Train Loss: 1.257933\n",
      "Epoch 75/100, Train Loss: 1.257302\n",
      "Epoch 76/100, Train Loss: 1.256624\n",
      "Epoch 77/100, Train Loss: 1.255938\n",
      "Epoch 78/100, Train Loss: 1.255292\n",
      "Epoch 79/100, Train Loss: 1.254608\n",
      "Epoch 80/100, Train Loss: 1.253927\n",
      "Epoch 81/100, Train Loss: 1.253304\n",
      "Epoch 82/100, Train Loss: 1.252657\n",
      "Epoch 83/100, Train Loss: 1.251956\n",
      "Epoch 84/100, Train Loss: 1.251322\n",
      "Epoch 85/100, Train Loss: 1.250660\n",
      "Epoch 86/100, Train Loss: 1.250036\n",
      "Epoch 87/100, Train Loss: 1.249324\n",
      "Epoch 88/100, Train Loss: 1.248714\n",
      "Epoch 89/100, Train Loss: 1.248056\n",
      "Epoch 90/100, Train Loss: 1.247404\n",
      "Epoch 91/100, Train Loss: 1.246769\n",
      "Epoch 92/100, Train Loss: 1.246087\n",
      "Epoch 93/100, Train Loss: 1.245469\n",
      "Epoch 94/100, Train Loss: 1.244861\n",
      "Epoch 95/100, Train Loss: 1.244252\n",
      "Epoch 96/100, Train Loss: 1.243564\n",
      "Epoch 97/100, Train Loss: 1.242904\n",
      "Epoch 98/100, Train Loss: 1.242260\n",
      "Epoch 99/100, Train Loss: 1.241623\n",
      "Epoch 100/100, Train Loss: 1.240987\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "\n",
    "# Create PyTorch datasets and data loaders\n",
    "train_dataset = TensorDataset(X_train)\n",
    "test_dataset = TensorDataset(X_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 2  # Latent space dimension\n",
    "model = Autoencoder(input_size, hidden_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        inputs = data[0]\n",
    "        optimizer.zero_grad()\n",
    "        _, outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}')\n",
    "\n",
    "# Save the trained model weights\n",
    "torch.save(model.state_dict(), 'trained_model.pth')\n",
    "\n",
    "# Extract the latent space representations\n",
    "latent_representations = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for data, target in zip(test_loader, y_test):\n",
    "        inputs = data[0]\n",
    "        encoded, _ = model(inputs)\n",
    "        latent_representations.append(encoded.numpy())\n",
    "        labels.append(iris.target_names[target])\n",
    "        print(target)\n",
    "        #labels.extend([iris.target_names[label] for label in target])\n",
    "\n",
    "# Concatenate the latent representations and labels\n",
    "latent_representations = np.concatenate(latent_representations)\n",
    "#labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bac34bf-f2c6-4266-bd0f-6fe4ebe0a70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latent_representations[:, 0]),len(latent_representations[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c05f9603-1987-4da4-a4e6-717d2458c6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.08061126],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.0764538 ],\n",
       "       [0.        , 0.00746146],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.01901871],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.07510528],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.03869471],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.00798699, 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2cdf15a2-0e3c-4760-ab4c-008d4ad16116",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize the latent space\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatterplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_representations\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_representations\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mviridis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatent Dimension 1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\seaborn\\relational.py:615\u001b[0m, in \u001b[0;36mscatterplot\u001b[1;34m(data, x, y, hue, size, style, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatterplot\u001b[39m(\n\u001b[0;32m    607\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    608\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    613\u001b[0m ):\n\u001b[1;32m--> 615\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_ScatterPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    621\u001b[0m     p\u001b[38;5;241m.\u001b[39mmap_hue(palette\u001b[38;5;241m=\u001b[39mpalette, order\u001b[38;5;241m=\u001b[39mhue_order, norm\u001b[38;5;241m=\u001b[39mhue_norm)\n\u001b[0;32m    622\u001b[0m     p\u001b[38;5;241m.\u001b[39mmap_size(sizes\u001b[38;5;241m=\u001b[39msizes, order\u001b[38;5;241m=\u001b[39msize_order, norm\u001b[38;5;241m=\u001b[39msize_norm)\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\seaborn\\relational.py:396\u001b[0m, in \u001b[0;36m_ScatterPlotter.__init__\u001b[1;34m(self, data, variables, legend)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, variables\u001b[38;5;241m=\u001b[39m{}, legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    388\u001b[0m \n\u001b[0;32m    389\u001b[0m     \u001b[38;5;66;03m# TODO this is messy, we want the mapping to be agnostic about\u001b[39;00m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;66;03m# the kind of plot to draw, but for the time being we need to set\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;66;03m# this information so the SizeMapping can use it\u001b[39;00m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_size_range \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    393\u001b[0m         np\u001b[38;5;241m.\u001b[39mr_[\u001b[38;5;241m.5\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msquare(mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlines.markersize\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    394\u001b[0m     )\n\u001b[1;32m--> 396\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegend \u001b[38;5;241m=\u001b[39m legend\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\seaborn\\_base.py:634\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_ordered \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\seaborn\\_base.py:679\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 679\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m \u001b[43mPlotData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m     frame \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mframe\n\u001b[0;32m    681\u001b[0m     names \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mnames\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\seaborn\\_core\\data.py:58\u001b[0m, in \u001b[0;36mPlotData.__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     53\u001b[0m     data: DataSource,\n\u001b[0;32m     54\u001b[0m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[0;32m     55\u001b[0m ):\n\u001b[0;32m     57\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data_source(data)\n\u001b[1;32m---> 58\u001b[0m     frame, names, ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;241m=\u001b[39m frame\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m names\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\seaborn\\_core\\data.py:265\u001b[0m, in \u001b[0;36mPlotData._assign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    260\u001b[0m             ids[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m(val)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# Construct a tidy plot DataFrame. This will convert a number of\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# types automatically, aligning on index in case of pandas objects\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# TODO Note: this fails when variable specs *only* have scalars!\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frame, names, ids\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Visualize the latent space\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=latent_representations[:, 0], y=latent_representations[:, 1], hue=labels, palette='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.title('Latent Space Representation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9d6855a-d5b1-4d52-9ce1-4ced611eeaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n- Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n  Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n  Mathematical Statistics\" (John Wiley, NY, 1950).\\n- Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n  (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n- Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n  Structure and Classification Rule for Recognition in Partially Exposed\\n  Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n  Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n- Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n  on Information Theory, May 1972, 431-433.\\n- See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n  conceptual clustering system finds 3 classes in the data.\\n- Many, many more ...\\n\\n|details-end|\\n',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48225bea-850f-4d3d-b4cf-42c50bca415e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade8078e-9881-4e9d-8b3b-c4f17bc964ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de1b745-6c55-48df-9023-4b143545ac04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 178\\n:Number of Attributes: 13 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - Alcohol\\n    - Malic acid\\n    - Ash\\n    - Alcalinity of ash\\n    - Magnesium\\n    - Total phenols\\n    - Flavanoids\\n    - Nonflavanoid phenols\\n    - Proanthocyanins\\n    - Color intensity\\n    - Hue\\n    - OD280/OD315 of diluted wines\\n    - Proline\\n    - class:\\n        - class_0\\n        - class_1\\n        - class_2\\n\\n:Summary Statistics:\\n\\n============================= ==== ===== ======= =====\\n                                Min   Max   Mean     SD\\n============================= ==== ===== ======= =====\\nAlcohol:                      11.0  14.8    13.0   0.8\\nMalic Acid:                   0.74  5.80    2.34  1.12\\nAsh:                          1.36  3.23    2.36  0.27\\nAlcalinity of Ash:            10.6  30.0    19.5   3.3\\nMagnesium:                    70.0 162.0    99.7  14.3\\nTotal Phenols:                0.98  3.88    2.29  0.63\\nFlavanoids:                   0.34  5.08    2.03  1.00\\nNonflavanoid Phenols:         0.13  0.66    0.36  0.12\\nProanthocyanins:              0.41  3.58    1.59  0.57\\nColour Intensity:              1.3  13.0     5.1   2.3\\nHue:                          0.48  1.71    0.96  0.23\\nOD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\nProline:                       278  1680     746   315\\n============================= ==== ===== ======= =====\\n\\n:Missing Attribute Values: None\\n:Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners:\\n\\nForina, M. et al, PARVUS -\\nAn Extendible Package for Data Exploration, Classification and Correlation.\\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science.\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n(1) S. Aeberhard, D. Coomans and O. de Vel,\\nComparison of Classifiers in High Dimensional Settings,\\nTech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of\\nMathematics and Statistics, James Cook University of North Queensland.\\n(Also submitted to Technometrics).\\n\\nThe data was used with many others for comparing various\\nclassifiers. The classes are separable, though only RDA\\nhas achieved 100% correct classification.\\n(RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))\\n(All results using the leave-one-out technique)\\n\\n(2) S. Aeberhard, D. Coomans and O. de Vel,\\n\"THE CLASSIFICATION PERFORMANCE OF RDA\"\\nTech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of\\nMathematics and Statistics, James Cook University of North Queensland.\\n(Also submitted to Journal of Chemometrics).\\n\\n|details-end|\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset = load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bc1a84-e2d5-4c59-9f6d-062585284736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f14776d-8351-4bd6-9ce9-2bb71900cbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([124, 13]), torch.Size([54, 13]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d6571d-e37c-47fc-bca1-2bc594a285f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b4d257-c4e0-4ca0-9c1a-cd87db467657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e2723e9-9374-422b-81c9-a3d5ae69e997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e4df77c-3caa-4e74-b1fd-c96861397c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = len(dataset.feature_names)\n",
    "H = 50\n",
    "H2 = 12\n",
    "model = Autoencoder(D_in, H, H2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa05474a-595a-4cc2-9c4c-3bedcd71810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mse = customLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9835ff76-37be-4b52-8d1d-eeae90b56b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1500\n",
    "log_interval = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "857eb67a-6e01-4d32-972d-346a1e748d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (linear1): Linear(in_features=13, out_features=50, bias=True)\n",
       "  (lin_bn1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear2): Linear(in_features=50, out_features=12, bias=True)\n",
       "  (lin_bn2): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear3): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (lin_bn3): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=12, out_features=3, bias=True)\n",
       "  (bn1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc21): Linear(in_features=3, out_features=3, bias=True)\n",
       "  (fc22): Linear(in_features=3, out_features=3, bias=True)\n",
       "  (fc3): Linear(in_features=3, out_features=3, bias=True)\n",
       "  (fc_bn3): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=3, out_features=12, bias=True)\n",
       "  (fc_bn4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear4): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (lin_bn4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear5): Linear(in_features=12, out_features=50, bias=True)\n",
       "  (lin_bn5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear6): Linear(in_features=50, out_features=13, bias=True)\n",
       "  (lin_bn6): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a160aa1-ed37-453d-a2da-5367ece8b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        data = data.to(device).to(torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    if epoch % 200 == 0:        \n",
    "        print('====> Epoch: {} Average training loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(trainloader.dataset)))\n",
    "        train_losses.append(train_loss / len(trainloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a78416f-01a7-49e2-8307-79182d96ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for batch_idx, data in enumerate(testloader):\n",
    "            data = data.to(device).to(torch.float32)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "            if epoch % 200 == 0:        \n",
    "                print('====> Epoch: {} Average test loss: {:.4f}'.format(\n",
    "                    epoch, test_loss / len(testloader.dataset)))\n",
    "            test_losses.append(test_loss / len(testloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ea46963-38d3-4ca2-ab31-32f8f37eaac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 200 Average training loss: 13.3368\n",
      "====> Epoch: 200 Average test loss: 14.1931\n",
      "====> Epoch: 400 Average training loss: 11.5527\n",
      "====> Epoch: 400 Average test loss: 11.8054\n",
      "====> Epoch: 600 Average training loss: 9.7752\n",
      "====> Epoch: 600 Average test loss: 11.9003\n",
      "====> Epoch: 800 Average training loss: 8.9588\n",
      "====> Epoch: 800 Average test loss: 9.8614\n",
      "====> Epoch: 1000 Average training loss: 8.3919\n",
      "====> Epoch: 1000 Average test loss: 9.9363\n",
      "====> Epoch: 1200 Average training loss: 7.5658\n",
      "====> Epoch: 1200 Average test loss: 9.6052\n",
      "====> Epoch: 1400 Average training loss: 7.0090\n",
      "====> Epoch: 1400 Average test loss: 8.8501\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca3d30e9-1bef-44de-938d-4943cf725623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0125e-01, -4.1092e-01, -8.6919e-01, -1.2948e+00,  8.8519e-01,\n",
       "          5.5696e-01,  7.8093e-01, -6.6191e-01,  1.0412e+00, -8.0629e-02,\n",
       "          3.2283e-01,  8.9173e-01,  7.0137e-01],\n",
       "        [ 1.7891e-01, -2.7480e-01,  1.9202e-01, -1.3058e-01, -2.8748e-02,\n",
       "          5.5199e-01,  6.8846e-01, -6.0493e-01,  6.8843e-02, -3.1970e-01,\n",
       "          3.2762e-01,  1.0095e+00,  2.3109e-01],\n",
       "        [ 1.2009e-01,  9.1562e-01,  2.7403e-01,  5.2794e-01, -8.2547e-02,\n",
       "         -9.3469e-01, -1.1771e+00,  6.0149e-01, -7.3297e-01,  9.4879e-01,\n",
       "         -1.1487e+00, -1.2615e+00, -4.1227e-01],\n",
       "        [ 7.6353e-01, -5.7202e-01,  8.7160e-01, -1.7013e-01,  1.0368e+00,\n",
       "          6.1942e-01,  8.1148e-01, -2.1581e-01,  1.7758e-01,  4.4685e-02,\n",
       "          6.0197e-01,  6.6050e-01,  1.1582e+00],\n",
       "        [-8.8740e-01, -6.6023e-01, -8.5951e-01, -1.1303e-01, -9.3083e-01,\n",
       "          5.2852e-02, -3.4167e-02, -4.3076e-01, -2.7521e-01, -8.1222e-01,\n",
       "          4.3500e-01,  3.5468e-01, -8.6921e-01],\n",
       "        [ 2.4203e-01, -4.6112e-01,  1.1058e+00,  3.7407e-01,  7.8130e-01,\n",
       "          7.6676e-01,  8.2475e-01, -1.6835e-01,  3.1316e-01, -2.9920e-01,\n",
       "          7.4939e-01,  7.5129e-01,  5.7026e-01],\n",
       "        [-7.0818e-01, -3.3637e-01, -2.0742e-01,  4.2083e-02,  6.6203e-01,\n",
       "         -8.2931e-01, -6.1686e-01, -4.6669e-02, -9.1425e-01, -6.7875e-01,\n",
       "          1.1525e-01, -6.5445e-01, -6.8285e-01],\n",
       "        [ 1.2009e-01,  9.1562e-01,  2.7403e-01,  5.2794e-01, -8.2547e-02,\n",
       "         -9.3469e-01, -1.1771e+00,  6.0149e-01, -7.3297e-01,  9.4879e-01,\n",
       "         -1.1487e+00, -1.2615e+00, -4.1227e-01],\n",
       "        [-6.3358e-01,  4.7456e-02, -1.5031e-01, -5.4671e-02, -6.5176e-01,\n",
       "          8.1947e-01,  6.1758e-01, -7.0616e-01,  1.5585e-01, -5.0111e-01,\n",
       "         -6.2823e-02,  8.2175e-01, -5.4880e-01],\n",
       "        [ 1.2009e-01,  9.1562e-01,  2.7403e-01,  5.2794e-01, -8.2547e-02,\n",
       "         -9.3469e-01, -1.1771e+00,  6.0149e-01, -7.3297e-01,  9.4879e-01,\n",
       "         -1.1487e+00, -1.2615e+00, -4.1227e-01],\n",
       "        [ 3.7430e-01, -1.7032e-01,  1.6170e-03, -4.9524e-01,  1.0768e-01,\n",
       "          6.2292e-01,  7.1690e-01, -7.3989e-01,  2.1887e-02, -9.1231e-02,\n",
       "          1.5378e-01,  1.0282e+00,  4.5267e-01],\n",
       "        [ 1.2009e-01,  9.1562e-01,  2.7403e-01,  5.2794e-01, -8.2547e-02,\n",
       "         -9.3469e-01, -1.1771e+00,  6.0149e-01, -7.3297e-01,  9.4879e-01,\n",
       "         -1.1487e+00, -1.2615e+00, -4.1227e-01],\n",
       "        [ 3.3223e-02,  9.9259e-01, -2.7681e-01, -3.2973e-01, -3.7338e-01,\n",
       "          7.2840e-01,  6.6789e-01, -6.2934e-01,  6.8767e-01, -3.4630e-01,\n",
       "         -3.6412e-01,  7.8186e-01, -8.1084e-02],\n",
       "        [-5.1698e-01, -3.3496e-02, -6.6923e-02,  2.3953e-01,  4.1994e-01,\n",
       "         -9.7775e-01, -7.3531e-01,  3.0932e-01, -7.8904e-01, -2.8420e-01,\n",
       "         -3.2618e-01, -7.8617e-01, -5.6282e-01],\n",
       "        [ 1.2825e+00, -6.1678e-01,  4.5274e-01, -7.3091e-01,  1.0177e+00,\n",
       "          1.1692e+00,  1.1710e+00, -4.1705e-01,  6.3776e-01,  5.4699e-01,\n",
       "          5.5553e-01,  6.6563e-01,  1.7431e+00],\n",
       "        [-8.4035e-01, -3.1739e-01, -2.2297e-01,  8.1350e-02, -7.5786e-01,\n",
       "          6.1025e-01,  4.5165e-01, -6.3714e-01,  1.4461e-01, -6.0807e-01,\n",
       "          1.2924e-01,  6.7845e-01, -6.5979e-01],\n",
       "        [-8.8641e-01, -2.1393e-02,  2.0061e-01,  7.2590e-01, -1.0529e+00,\n",
       "         -8.4926e-01, -6.1945e-01,  1.0522e+00, -2.9001e-01, -5.7116e-01,\n",
       "          1.8721e-01, -3.2599e-01, -6.9742e-01],\n",
       "        [-1.0666e+00, -9.2336e-02,  2.3767e-01,  8.1497e-01, -1.2052e+00,\n",
       "         -7.8689e-01, -5.5131e-01,  1.1089e+00, -1.3833e-01, -7.6423e-01,\n",
       "          4.4802e-01, -2.2650e-01, -7.9561e-01],\n",
       "        [ 1.0149e+00, -4.8315e-01, -1.8703e-01, -8.0593e-01,  6.5102e-01,\n",
       "          9.0473e-01,  9.6222e-01, -6.9473e-01,  6.6342e-01,  2.4380e-01,\n",
       "          3.8534e-01,  9.4460e-01,  9.9353e-01],\n",
       "        [-8.6697e-01, -3.4896e-01,  9.6603e-01,  1.1425e+00,  5.5969e-02,\n",
       "          4.0118e-01,  5.0089e-01,  5.1474e-01,  4.2300e-01, -8.8028e-01,\n",
       "          1.2071e+00,  5.2898e-01, -5.8255e-01],\n",
       "        [ 9.1461e-01, -5.5236e-01, -8.7833e-01, -1.7263e+00,  2.9721e-01,\n",
       "          1.2203e+00,  1.4000e+00, -6.1763e-01,  3.0657e+00,  5.9268e-01,\n",
       "          8.3204e-01,  3.4837e-01,  1.7042e+00],\n",
       "        [-7.5896e-01,  1.8728e+00, -8.2969e-01,  1.6992e-01, -7.0129e-01,\n",
       "          7.8373e-01,  6.6034e-01, -5.3546e-01,  2.1741e+00, -7.5471e-01,\n",
       "         -7.1493e-01,  5.7534e-01, -7.0964e-01],\n",
       "        [ 4.2153e-02,  8.1512e-01,  2.8064e-01,  5.1926e-01, -2.1009e-01,\n",
       "         -9.2394e-01, -1.0959e+00,  6.2279e-01, -6.8283e-01,  7.9061e-01,\n",
       "         -1.0216e+00, -1.1478e+00, -4.2127e-01],\n",
       "        [ 1.2009e-01,  9.1562e-01,  2.7403e-01,  5.2794e-01, -8.2547e-02,\n",
       "         -9.3469e-01, -1.1771e+00,  6.0149e-01, -7.3297e-01,  9.4879e-01,\n",
       "         -1.1487e+00, -1.2615e+00, -4.1227e-01],\n",
       "        [ 1.2009e-01,  9.1562e-01,  2.7403e-01,  5.2794e-01, -8.2547e-02,\n",
       "         -9.3469e-01, -1.1771e+00,  6.0149e-01, -7.3297e-01,  9.4879e-01,\n",
       "         -1.1487e+00, -1.2615e+00, -4.1227e-01],\n",
       "        [ 1.2175e-01,  9.4167e-01,  2.6243e-01,  4.9224e-01,  2.0761e-01,\n",
       "         -9.0522e-01, -1.1648e+00,  5.0098e-01, -8.8054e-01,  8.9568e-01,\n",
       "         -1.1721e+00, -1.2545e+00, -3.6093e-01],\n",
       "        [-9.5509e-01, -6.6119e-01, -7.6742e-01,  1.8994e-01, -5.7340e-01,\n",
       "         -4.7605e-01, -1.9021e-01, -9.9259e-02, -4.1578e-01, -8.5813e-01,\n",
       "          3.0262e-01,  1.0566e-01, -7.6211e-01],\n",
       "        [-5.0607e-01, -4.9795e-01,  1.0645e+00,  9.2748e-01,  2.8748e-01,\n",
       "          5.9120e-01,  6.4832e-01,  2.0023e-01,  4.1926e-01, -6.8508e-01,\n",
       "          1.0681e+00,  6.5048e-01, -3.2024e-01],\n",
       "        [-9.5780e-01, -7.8595e-02,  2.0115e-01,  7.5706e-01, -1.0032e+00,\n",
       "         -7.5777e-01, -5.2755e-01,  9.8270e-01, -1.3849e-01, -6.7529e-01,\n",
       "          3.8635e-01, -2.6774e-01, -7.7922e-01],\n",
       "        [ 1.3629e+00, -6.0119e-01, -4.7256e-02, -9.8947e-01,  7.7474e-01,\n",
       "          1.1989e+00,  1.1963e+00, -5.8350e-01,  7.6824e-01,  5.9227e-01,\n",
       "          4.6772e-01,  7.5406e-01,  1.6392e+00],\n",
       "        [ 6.1489e-01, -3.8515e-01, -3.7898e-01, -7.9593e-01,  2.7762e-01,\n",
       "          4.9412e-01,  7.3845e-01, -7.6589e-01,  2.6105e-01, -1.4454e-02,\n",
       "          1.8353e-01,  1.0278e+00,  5.9746e-01],\n",
       "        [-1.1476e+00, -2.9756e-01,  9.9412e-02,  8.2019e-01, -1.2743e+00,\n",
       "         -7.5094e-01, -4.5654e-01,  1.1304e+00, -1.9165e-01, -1.0089e+00,\n",
       "          6.0766e-01,  6.0287e-03, -8.2350e-01],\n",
       "        [ 1.2009e-01,  9.1562e-01,  2.7403e-01,  5.2794e-01, -8.2547e-02,\n",
       "         -9.3469e-01, -1.1771e+00,  6.0149e-01, -7.3297e-01,  9.4879e-01,\n",
       "         -1.1487e+00, -1.2615e+00, -4.1227e-01],\n",
       "        [ 1.1139e+00, -4.8457e-01, -5.1942e-01, -1.3179e+00,  2.6171e-01,\n",
       "          1.1134e+00,  1.2088e+00, -7.8219e-01,  1.3197e+00,  5.3130e-01,\n",
       "          4.1721e-01,  7.6815e-01,  1.2609e+00],\n",
       "        [ 9.4067e-01, -5.4925e-01, -4.7751e-01, -1.1239e+00,  5.5564e-01,\n",
       "          9.8456e-01,  1.0498e+00, -8.8246e-01,  1.0171e+00,  2.5095e-01,\n",
       "          3.5692e-01,  9.9616e-01,  9.7376e-01],\n",
       "        [ 1.1796e+00, -5.3770e-01, -1.6971e-01, -8.9044e-01,  6.6317e-01,\n",
       "          1.0088e+00,  1.0656e+00, -6.3521e-01,  6.9557e-01,  4.2345e-01,\n",
       "          4.2294e-01,  8.0403e-01,  1.3033e+00],\n",
       "        [ 1.2009e-01,  9.1562e-01,  2.7403e-01,  5.2794e-01, -8.2547e-02,\n",
       "         -9.3469e-01, -1.1771e+00,  6.0149e-01, -7.3297e-01,  9.4879e-01,\n",
       "         -1.1487e+00, -1.2615e+00, -4.1227e-01],\n",
       "        [ 1.2009e-01,  9.1562e-01,  2.7403e-01,  5.2794e-01, -8.2547e-02,\n",
       "         -9.3469e-01, -1.1771e+00,  6.0149e-01, -7.3297e-01,  9.4879e-01,\n",
       "         -1.1487e+00, -1.2615e+00, -4.1227e-01],\n",
       "        [-2.7651e-01,  2.6197e-01, -2.3079e-01, -2.7554e-01, -4.1325e-01,\n",
       "          7.7104e-01,  6.3821e-01, -6.9418e-01,  2.0435e-01, -3.8497e-01,\n",
       "         -1.3924e-01,  8.3953e-01, -2.7629e-01],\n",
       "        [-2.2824e-02,  7.5319e-01,  2.7206e-01,  5.2692e-01, -2.7341e-01,\n",
       "         -9.2611e-01, -1.0620e+00,  6.5117e-01, -6.4230e-01,  6.8917e-01,\n",
       "         -9.3430e-01, -1.0932e+00, -4.4237e-01],\n",
       "        [ 6.5962e-01, -5.0531e-01,  5.9385e-01, -2.3945e-01,  6.3307e-01,\n",
       "          7.0193e-01,  8.0761e-01, -4.7078e-01,  2.9886e-01, -1.0553e-01,\n",
       "          5.4692e-01,  8.4379e-01,  8.6845e-01],\n",
       "        [-6.9174e-01, -6.1835e-01, -1.1318e+00, -4.8372e-01, -7.2984e-01,\n",
       "         -1.8328e-01, -2.5709e-01, -4.2421e-01, -8.5071e-01, -9.1055e-01,\n",
       "          4.6612e-01,  1.1207e-01, -8.2676e-01],\n",
       "        [-8.3303e-01, -3.9231e-01,  4.2365e-01,  8.5630e-01, -4.3911e-01,\n",
       "          3.6901e-01,  4.5862e-01,  2.5235e-01,  4.1932e-01, -8.3127e-01,\n",
       "          1.0124e+00,  6.4119e-01, -6.3805e-01],\n",
       "        [-1.0850e+00, -3.4601e-01,  3.8542e-02,  7.6723e-01, -1.1713e+00,\n",
       "         -4.8039e-01, -2.6030e-01,  8.0333e-01, -1.3064e-01, -1.0191e+00,\n",
       "          7.2080e-01,  2.0021e-01, -8.5610e-01],\n",
       "        [ 1.2009e-01,  9.1562e-01,  2.7403e-01,  5.2794e-01, -8.2547e-02,\n",
       "         -9.3469e-01, -1.1771e+00,  6.0149e-01, -7.3297e-01,  9.4879e-01,\n",
       "         -1.1487e+00, -1.2615e+00, -4.1227e-01],\n",
       "        [ 1.0481e+00, -4.9330e-01, -1.5684e-02, -7.0361e-01,  6.7947e-01,\n",
       "          8.8468e-01,  9.5999e-01, -5.9770e-01,  5.9520e-01,  2.6381e-01,\n",
       "          4.1179e-01,  8.6956e-01,  1.1002e+00],\n",
       "        [-8.0901e-01, -6.3820e-01, -2.2585e+00, -9.8427e-01, -4.9115e-01,\n",
       "         -5.2721e-01, -9.1452e-01, -5.2852e-01, -1.3882e+00, -1.3510e+00,\n",
       "          6.3173e-01, -6.3998e-01, -6.0663e-01],\n",
       "        [-1.1025e+00, -3.3544e-01,  1.1538e-01,  8.0151e-01, -1.2136e+00,\n",
       "         -5.1770e-01, -2.9439e-01,  8.9790e-01, -1.5507e-01, -1.0253e+00,\n",
       "          7.2250e-01,  1.8755e-01, -8.4578e-01],\n",
       "        [-4.7179e-01,  2.5013e-02,  8.8298e-02,  1.5470e-01,  9.0367e-01,\n",
       "         -9.8643e-01, -7.6926e-01,  1.3984e-01, -9.1792e-01, -1.7823e-01,\n",
       "         -4.0477e-01, -9.8736e-01, -4.3185e-01],\n",
       "        [ 1.3045e+00, -5.8733e-01,  1.4948e-01, -8.5618e-01,  8.2742e-01,\n",
       "          1.1454e+00,  1.1597e+00, -5.1533e-01,  6.8670e-01,  5.4048e-01,\n",
       "          4.9445e-01,  7.2633e-01,  1.6229e+00],\n",
       "        [-7.7086e-01, -5.4448e-01, -9.9356e-01, -3.4809e-01, -8.4304e-01,\n",
       "         -4.0829e-02, -1.1269e-01, -4.4532e-01, -5.1226e-01, -8.6963e-01,\n",
       "          4.2644e-01,  2.3806e-01, -9.3539e-01],\n",
       "        [ 1.1775e+00, -5.5860e-01, -3.3707e-01, -1.0306e+00,  6.4255e-01,\n",
       "          1.0650e+00,  1.1074e+00, -7.2005e-01,  8.1391e-01,  4.4893e-01,\n",
       "          4.1287e-01,  8.4797e-01,  1.2865e+00],\n",
       "        [ 9.2661e-01, -7.3862e-01,  1.2290e+00, -2.4120e-01,  1.5510e+00,\n",
       "          1.1131e+00,  1.1707e+00, -1.3629e-01,  4.4576e-01,  3.6522e-01,\n",
       "          8.4786e-01,  4.8090e-01,  1.8153e+00],\n",
       "        [-3.0322e-01,  3.3678e-01,  2.8921e-01,  4.4911e-01,  9.8316e-01,\n",
       "         -9.8344e-01, -1.0300e+00,  2.0488e-01, -8.7696e-01,  2.0132e-01,\n",
       "         -7.2999e-01, -1.1413e+00, -3.8347e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(testloader):\n",
    "        data = data.to(device).to(torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        \n",
    "scaler = trainloader.dataset.standardizer\n",
    "recon_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d5e631c-5014-42ff-b76e-2372a1a53e09",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.60125285 -0.4109178  -0.8691857  -1.2948145   0.88518506  0.5569587\n  0.78092647 -0.6619064   1.0412297  -0.08062924  0.3228297   0.89173126\n  0.70137316].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recon_row \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m real_row \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(testloader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1085\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1082\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1084\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1085\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\sklearn\\utils\\validation.py:1035\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1029\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1030\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1031\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1032\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1033\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1034\u001b[0m             )\n\u001b[1;32m-> 1035\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1038\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1039\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1041\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.60125285 -0.4109178  -0.8691857  -1.2948145   0.88518506  0.5569587\n  0.78092647 -0.6619064   1.0412297  -0.08062924  0.3228297   0.89173126\n  0.70137316].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "recon_row = scaler.inverse_transform(recon_batch[0].cpu().numpy())\n",
    "real_row = scaler.inverse_transform(testloader.dataset.x[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bede3f-e6b1-447b-ac1c-6a3dd85bb22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0977d356-3e7b-4932-a235-7d2e5adc93ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(2, 54, 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_row\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\pandas\\core\\frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    825\u001b[0m         )\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\pandas\\core\\internals\\construction.py:314\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    308\u001b[0m     _copy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    309\u001b[0m         copy_on_sanitize\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, dtype))\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    312\u001b[0m     )\n\u001b[0;32m    313\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, copy\u001b[38;5;241m=\u001b[39m_copy)\n\u001b[1;32m--> 314\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     values \u001b[38;5;241m=\u001b[39m _prep_ndarraylike(values, copy\u001b[38;5;241m=\u001b[39mcopy_on_sanitize)\n",
      "File \u001b[1;32m~\\Documents\\tabulartorch\\cuda_dev\\lib\\site-packages\\pandas\\core\\internals\\construction.py:592\u001b[0m, in \u001b[0;36m_ensure_2d\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    590\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(2, 54, 13)"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.stack((recon_row, real_row)), columns = dataset.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91810ae6-d385-41d2-9640-a0ba49c2e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack((recon_row, real_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a369a63-e040-4c2b-ae97-6a7f53504b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
